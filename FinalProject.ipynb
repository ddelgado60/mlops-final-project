{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StiQr32JOtwC"
   },
   "source": [
    "**Name**\n",
    "\n",
    "* **Yu-Chih (Wisdom) Chen**\n",
    "* **Devon Delgado**\n",
    "* **Xiaobing Xu**\n",
    "* **Peter Ye**\n",
    "\n",
    "**Date**\n",
    "\n",
    "**11/16/2024**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YtXV9oglkX9"
   },
   "source": [
    "# Fake Job Description Prediction Dataset\n",
    "\n",
    "## Overview\n",
    "This dataset is designed for developing classification models to identify fraudulent job postings. It contains approximately 18,000 job descriptions, with around 800 labeled as fake.\n",
    "\n",
    "## Dataset Details\n",
    "- **Total Entries**: ~18,000 job descriptions\n",
    "- **Fraudulent Entries**: ~800\n",
    "- **Data Types**: Textual information and meta-information about jobs\n",
    "\n",
    "## Source\n",
    "The University of the Aegean | Laboratory of Information & Communication Systems Security\n",
    "(http://emscad.samos.aegean.gr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:08.222607Z",
     "start_time": "2024-11-20T10:50:04.509470Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICnYzB7glhqF",
    "outputId": "ebbdf12d-61a5-4a02-e44a-ec84710f8d49"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from feast import FeatureStore\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from pandarallel import pandarallel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from utli import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkE-hkKVnMId"
   },
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:09.244013Z",
     "start_time": "2024-11-20T10:50:08.237016Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uj-tV8L7n8Sf",
    "outputId": "92796236-7def-42be-9346-11a0c1fac6d0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_job_postings.csv') # Change it to data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:43:39.247690Z",
     "start_time": "2024-11-20T10:43:39.238478Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TnF9OM-PY6O"
   },
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:43:40.324801Z",
     "start_time": "2024-11-20T10:43:40.321568Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33vkBC_-Ef0j",
    "outputId": "c7778976-bbd0-4ea3-c618-b180212ff532"
   },
   "outputs": [],
   "source": [
    "# Get the dimensions of the Dataset\n",
    "print(\"Dimensions of the Dataset (Rows, Columns):\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:43:40.578584Z",
     "start_time": "2024-11-20T10:43:40.575908Z"
    },
    "id": "slJ_HrFmEghx"
   },
   "outputs": [],
   "source": [
    "# Removing any leading, and trailing whitespaces in columns\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:12.851493Z",
     "start_time": "2024-11-19T08:11:12.823041Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv4OtoFNYHfa",
    "outputId": "06375746-5527-462a-b8d8-c075c8778093"
   },
   "outputs": [],
   "source": [
    "# Check if any duplicate rows in dataset\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:14.140461Z",
     "start_time": "2024-11-19T08:11:14.126848Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avFAzpD1Pp-S",
    "outputId": "aeb67357-cd7c-41f1-caec-8c91eea755ff"
   },
   "outputs": [],
   "source": [
    "# Getting an overview of the features and their types in the dataset\n",
    "print(\"Overview of the features and their types:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:18.343541Z",
     "start_time": "2024-11-19T08:11:18.338670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3lyBY4APs2j",
    "outputId": "3bc37e05-6dcf-4847-c897-ac11d9be38ce"
   },
   "outputs": [],
   "source": [
    "# Count the number of columns with dtype 'object'\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "num_object_cols = len(object_cols)\n",
    "\n",
    "# Count the number of columns with dtype 'int64'\n",
    "int_cols = df.select_dtypes(include=['int64']).columns\n",
    "num_int_cols = len(int_cols)\n",
    "\n",
    "print(f\"Number of columns with object dtype: {num_object_cols}\")\n",
    "print(f\"Number of columns with int64 dtype: {num_int_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBoAwEgmPxvP"
   },
   "source": [
    "### a. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:21.299107Z",
     "start_time": "2024-11-19T08:11:21.288157Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsKSBOl_Pv9H",
    "outputId": "3dc24c3a-4f93-41a3-80d8-760487904b72"
   },
   "outputs": [],
   "source": [
    "print(\"Display Missing values in the dataset: \")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:26.469626Z",
     "start_time": "2024-11-19T08:11:26.460541Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0C3n6l8Qzjf",
    "outputId": "f56c16e0-fe94-43e2-eb6b-5dbc5ff786a7"
   },
   "outputs": [],
   "source": [
    "# View percentage of missing values per column\n",
    "print('Percent of Null Values in Each Column:\\n')\n",
    "print(df.isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:28.955267Z",
     "start_time": "2024-11-19T08:11:28.769972Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "ioy2MPOXQ93p",
    "outputId": "88a37641-0644-4fe9-8928-46058b07e83e"
   },
   "outputs": [],
   "source": [
    "# Count and display percentage of missing values\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "missing_percent.plot(kind='bar', color='skyblue')\n",
    "plt.title('Percentage of Missing Values by Column')\n",
    "plt.ylabel('% of Missing Values')\n",
    "plt.xlabel('Columns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFjtg1Si9xsE"
   },
   "source": [
    "### b. Visualizatioin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:48.589142Z",
     "start_time": "2024-11-19T08:11:48.567966Z"
    },
    "id": "IYMUFaU29-Et"
   },
   "outputs": [],
   "source": [
    "#Differentiate categorical data and numerical data\n",
    "df_num = df[['telecommuting','has_company_logo','has_questions','fraudulent','salary_range']]\n",
    "df_cat = df[['title', 'location','company_profile', 'requirements','employment_type',\n",
    "       'required_experience', 'required_education', 'industry', 'function']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:49.208415Z",
     "start_time": "2024-11-19T08:11:49.055971Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "oz5iWQxj-GeG",
    "outputId": "8f4fcfe7-2c23-4649-ea8d-49c080a3d999"
   },
   "outputs": [],
   "source": [
    "# Checking for Outliers in numerical data\n",
    "plt.figure(figsize=[8,6])\n",
    "sns.boxplot(data = df_num)\n",
    "plt.title(\"Numerical Data of Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:11:50.087205Z",
     "start_time": "2024-11-19T08:11:49.837331Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "7q5SYlA_-Rv5",
    "outputId": "ed68bec3-738d-41db-f8ad-6bede202a93a"
   },
   "outputs": [],
   "source": [
    "# Plots to see the distribution of the continuous features individually\n",
    "plt.figure(figsize= (25,20))\n",
    "plt.subplot(3,3,1)\n",
    "# Convert 'employment_type' to string type before plotting\n",
    "plt.hist(df.employment_type.astype(str), color='orange', edgecolor = 'black', alpha = 0.7)\n",
    "plt.xlabel('\\nEmployment type')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "# Convert 'required_experience' to string type before plotting\n",
    "plt.hist(df.required_experience.astype(str), color='lightblue', edgecolor = 'black', alpha = 0.7)\n",
    "plt.xlabel('\\nRequired Experience')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "plt.hist(df.fraudulent, color='red', edgecolor = 'black', alpha = 0.7)\n",
    "plt.xlabel('\\nFraud')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:13:05.523667Z",
     "start_time": "2024-11-19T08:13:05.152809Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "KRfoYQwP2IKt",
    "outputId": "1a9d9518-a36c-432e-b8c4-c8bcae0a174d"
   },
   "outputs": [],
   "source": [
    "# Number of Job Function\n",
    "plt.figure(figsize=(48, 20))\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Number of Job Function\", fontsize=20)\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(x='function', data=df, color='blue')  # Adjust color if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:13:11.578770Z",
     "start_time": "2024-11-19T08:13:11.399162Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "-NGHTnww2IKt",
    "outputId": "1c12f76f-7a48-4768-8c97-2f867ddb78e4"
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of fraudulent postings by function\n",
    "fraudulent_summary = df.groupby('function')['fraudulent'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(25, 8))\n",
    "sns.lineplot(data=fraudulent_summary, x='function', y='fraudulent', marker='o')\n",
    "plt.title('Fraudulent Postings by Function', fontsize = 20)\n",
    "plt.xlabel('Function')\n",
    "plt.ylabel('Sum of Fraudulent Postings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:15:10.760897Z",
     "start_time": "2024-11-19T08:15:10.682255Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "CGkpDflw2IKt",
    "outputId": "ef796ef3-c1b8-44a8-ef55-ed6e034130cc"
   },
   "outputs": [],
   "source": [
    "# Bar plot for fraudulent (target) feature\n",
    "fraud_colors = ['blue', 'red']\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='fraudulent', data=df, hue='fraudulent', palette=fraud_colors, dodge=False)\n",
    "plt.title('Distribution of Fraudulent Job Postings')\n",
    "plt.xlabel('Fraudulent')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:15:28.222Z",
     "start_time": "2024-11-19T08:15:27.490912Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "id": "BxxGvz6e2IKu",
    "outputId": "55f68e59-5d29-4562-8960-6787992e5dbd"
   },
   "outputs": [],
   "source": [
    "# Bar plot for employment_type\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='employment_type', y='fraudulent', estimator=sum, hue='employment_type', dodge=False, palette='Set2')\n",
    "plt.title('Fraudulent Postings by Employment Type')\n",
    "plt.xlabel('Employment Type')\n",
    "plt.ylabel('Sum of Fraudulent Postings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:15:39.440666Z",
     "start_time": "2024-11-19T08:15:38.744287Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "gsNHUHsc2IKu",
    "outputId": "d0cecc98-7027-4532-9b56-89af0c7aa5b8"
   },
   "outputs": [],
   "source": [
    "# Bar plot for required_experience\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df, x='required_experience', y='fraudulent', estimator=sum, hue='required_experience', dodge=False, palette='Set1')\n",
    "plt.title('Fraudulent Postings by Required Experience')\n",
    "plt.xlabel('Required Experience')\n",
    "plt.ylabel('Sum of Fraudulent Postings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T08:15:51.588153Z",
     "start_time": "2024-11-19T08:15:50.945541Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 964
    },
    "id": "XAF89qbH2IKu",
    "outputId": "62f4f328-4c73-493d-f77d-b659b9185da2"
   },
   "outputs": [],
   "source": [
    "# Bar plot for required_education\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(data=df, x='required_education', y='fraudulent', estimator=sum, hue='required_education', dodge=False, palette='Set3')\n",
    "plt.title('Fraudulent Postings by Required Education')\n",
    "plt.xlabel('Required Education')\n",
    "plt.ylabel('Sum of Fraudulent Postings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWOvAaja2IKu"
   },
   "source": [
    "### c. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:54.000514Z",
     "start_time": "2024-11-20T10:50:15.493308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "df_selected = select_features(df)\n",
    "\n",
    "# Prepare initial features\n",
    "df_processed = prepare_initial_features(df_selected)\n",
    "\n",
    "# Create feature stores\n",
    "structured_features, label_encoders = create_structured_features(df_processed)\n",
    "text_features = create_text_features(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:57.334460Z",
     "start_time": "2024-11-20T10:50:57.331870Z"
    }
   },
   "outputs": [],
   "source": [
    "print_feature_summary(structured_features, text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:59.553617Z",
     "start_time": "2024-11-20T10:50:59.550814Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset target variable\n",
    "target_features = df[['fraudulent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:50:59.822879Z",
     "start_time": "2024-11-20T10:50:59.811298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add PK column \n",
    "for df in [structured_features, text_features, target_features]:\n",
    "        if 'job_id' in df.columns:\n",
    "            df.drop(columns=['job_id'], inplace=True)\n",
    "    \n",
    "    # Add incremental job_id as the first column\n",
    "structured_features.insert(0, 'job_id', range(1, len(structured_features) + 1))\n",
    "text_features.insert(0, 'job_id', range(1, len(text_features) + 1))\n",
    "target_features.insert(0, 'job_id', range(1, len(target_features) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:00.009623Z",
     "start_time": "2024-11-20T10:51:00.005201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add an event_timestamp column with today's timestamp\n",
    "structured_features['event_timestamp'] = pd.Timestamp.now()\n",
    "text_features['event_timestamp'] = pd.Timestamp.now()\n",
    "target_features['event_timestamp'] = pd.Timestamp.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:00.214077Z",
     "start_time": "2024-11-20T10:51:00.203038Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_convert = [\n",
    "    \"title_cleaned\",\n",
    "    \"description_cleaned\",\n",
    "    \"requirements_cleaned\",\n",
    "    \"company_profile_cleaned\",\n",
    "    \"benefits_cleaned\"\n",
    "]\n",
    "\n",
    "text_features[columns_to_convert] = text_features[columns_to_convert].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:00.748391Z",
     "start_time": "2024-11-20T10:51:00.740734Z"
    }
   },
   "outputs": [],
   "source": [
    "text_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:01.461171Z",
     "start_time": "2024-11-20T10:51:01.452409Z"
    }
   },
   "outputs": [],
   "source": [
    "structured_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:01.916697Z",
     "start_time": "2024-11-20T10:51:01.912116Z"
    }
   },
   "outputs": [],
   "source": [
    "target_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuDtaB44-ZcB"
   },
   "source": [
    "## 3. Feature Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Structured Feature Store\n",
    "\n",
    "The structured feature store contains processed numerical and categorical features. These features are ready for use in traditional machine learning models.\n",
    "\n",
    "#### **(1) Label Encoded Categorical Features**\n",
    "These categorical features have been converted to numerical values using label encoding:\n",
    "- `location`: Job locations (e.g., \"US, NY\" → 1, \"UK, London\" → 2)\n",
    "- `employment_type`: Job types (e.g., \"Full-time\" → 0, \"Part-time\" → 1)\n",
    "- `required_experience`: Experience levels (e.g., \"Entry Level\" → 0, \"Senior\" → 1)\n",
    "- `required_education`: Education requirements (e.g., \"Bachelor's\" → 0, \"Master's\" → 1)\n",
    "- `industry`: Company industries (e.g., \"Technology\" → 0, \"Healthcare\" → 1)\n",
    "- `function`: Job functions (e.g., \"Engineering\" → 0, \"Sales\" → 1)\n",
    "\n",
    "#### **(2) Binary Features**\n",
    "Simple 0/1 indicators:\n",
    "- `telecommuting`: Remote work indicator (1=yes, 0=no)\n",
    "- `has_company_logo`: Company logo presence (1=yes, 0=no)\n",
    "- `has_questions`: Screening questions presence (1=yes, 0=no)\n",
    "- `no_logo_no_questions`: Combined feature (1=no logo & no questions, 0=otherwise)\n",
    "\n",
    "### **(3) Frequency Encoded Features**\n",
    "Represents how common each category is in the dataset:\n",
    "- `location_freq`: Location frequency (e.g., 0.25 = appears in 25% of postings)\n",
    "- `employment_type_freq`: Employment type frequency\n",
    "- `required_experience_freq`: Experience level frequency\n",
    "- `required_education_freq`: Education requirement frequency\n",
    "- `industry_freq`: Industry frequency\n",
    "- `function_freq`: Job function frequency\n",
    "\n",
    "### **(4) Text Length Features**\n",
    "Character counts of cleaned text fields:\n",
    "- `title_length`: Job title length\n",
    "- `description_length`: Job description length\n",
    "- `requirements_length`: Requirements text length\n",
    "- `company_profile_length`: Company profile length\n",
    "- `benefits_length`: Benefits text length\n",
    "\n",
    "### **(5) Missing Value Indicators**\n",
    "Binary flags (0/1) indicating missing values in original data:\n",
    "- Various columns ending with `_is_missing`\n",
    "\n",
    "## B. Text Feature Store\n",
    "\n",
    "The text feature store contains cleaned and processed text data, ready for natural language processing tasks.\n",
    "\n",
    "### **(1) Cleaned Text Features**\n",
    "Each text field has been processed to remove noise and standardize format:\n",
    "\n",
    "- `title_cleaned`\n",
    "  - Original: \"Senior Software Engineer (Python/Django)\"\n",
    "  - Cleaned: \"senior software engineer python django\"\n",
    "\n",
    "- `description_cleaned`\n",
    "  - Original: \"We are looking for a talented Software Engineer...\"\n",
    "  - Cleaned: \"looking talented software engineer...\"\n",
    "\n",
    "- `requirements_cleaned`\n",
    "  - Original: \"5+ years of Python experience required\"\n",
    "  - Cleaned: \"years python experience required\"\n",
    "\n",
    "- `company_profile_cleaned`\n",
    "  - Original: \"We're a fast-growing tech company...\"\n",
    "  - Cleaned: \"fast growing tech company\"\n",
    "\n",
    "- `benefits_cleaned`\n",
    "  - Original: \"401(k), Health Insurance, Flexible Hours\"\n",
    "  - Cleaned: \"health insurance flexible hours\"\n",
    "\n",
    "## C. Target Feature Store\n",
    "\n",
    "The target feature store only contains target variable 'fraudulent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Initialize the Feast repo called job repo to current directory & Save data to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T21:40:36.599414Z",
     "start_time": "2024-11-19T21:40:34.528298Z"
    }
   },
   "outputs": [],
   "source": [
    "!feast init -m job_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:06.892860Z",
     "start_time": "2024-11-20T10:51:06.446657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save features\n",
    "save_features(structured_features, text_features, target_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Define feature stores and schema for job_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:07.857815Z",
     "start_time": "2024-11-20T10:51:07.853013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update feature_store.yaml\n",
    "feature_store_yaml_content = \"\"\"\n",
    "project: job_project\n",
    "registry: data/registry.db\n",
    "provider: local\n",
    "online_store:\n",
    "    type: sqlite\n",
    "    path: data/online_store.db\n",
    "offline_store:\n",
    "    type: file\n",
    "entity_key_serialization_version: 2\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to feature_store.yaml\n",
    "with open('job_repo/feature_repo/feature_store.yaml', 'w') as f:\n",
    "    f.write(feature_store_yaml_content.strip())\n",
    "\n",
    "print(\"Updated feature_store.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Create features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:09.176624Z",
     "start_time": "2024-11-20T10:51:09.170857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create features.py file\n",
    "features_py_content = '''\n",
    "from datetime import timedelta\n",
    "from feast import Entity, FeatureView, Field, FileSource, Project\n",
    "from feast.types import Float32, String, Int64\n",
    "\n",
    "# Define a project for the feature repo\n",
    "project = Project(name=\"job_project\", description=\"A project for job data\")\n",
    "\n",
    "# Define the entity\n",
    "job = Entity(\n",
    "    name=\"job_id\",\n",
    "    join_keys=[\"job_id\"],\n",
    "    description=\"Unique identifier for job\",\n",
    ")\n",
    "\n",
    "# Define the Structured Feature data source\n",
    "job_structured_data_source = FileSource(\n",
    "    name='job_structured_data',\n",
    "    path=\"data/structured_features.parquet\",\n",
    "    timestamp_field=\"event_timestamp\")\n",
    "\n",
    "# Define the Structured Feature\n",
    "job_structured_features = FeatureView(\n",
    "    name=\"job_structured_features_view\",\n",
    "    entities=[job],\n",
    "    ttl=timedelta(days=1),\n",
    "    schema=[\n",
    "        Field(name=\"location\", dtype=Int64),\n",
    "        Field(name=\"employment_type\", dtype=Int64),\n",
    "        Field(name=\"required_experience\", dtype=Int64),\n",
    "        Field(name=\"required_education\", dtype=Int64),\n",
    "        Field(name=\"industry\", dtype=Int64),\n",
    "        Field(name=\"function\", dtype=Int64),\n",
    "        Field(name=\"telecommuting\", dtype=Int64),\n",
    "        Field(name=\"has_company_logo\", dtype=Int64),\n",
    "        Field(name=\"has_questions\", dtype=Int64),\n",
    "        Field(name=\"no_logo_no_questions\", dtype=Int64),\n",
    "        Field(name=\"location_freq\", dtype=Float32),\n",
    "        Field(name=\"employment_type_freq\", dtype=Float32),\n",
    "        Field(name=\"required_experience_freq\", dtype=Float32),\n",
    "        Field(name=\"required_education_freq\", dtype=Float32),\n",
    "        Field(name=\"industry_freq\", dtype=Float32),\n",
    "        Field(name=\"function_freq\", dtype=Float32),\n",
    "        Field(name=\"description_is_missing\", dtype=Int64),\n",
    "        Field(name=\"requirements_is_missing\", dtype=Int64),\n",
    "        Field(name=\"company_profile_is_missing\", dtype=Int64),\n",
    "        Field(name=\"benefits_is_missing\", dtype=Int64),\n",
    "        Field(name=\"location_is_missing\", dtype=Int64),\n",
    "        Field(name=\"employment_type_is_missing\", dtype=Int64),\n",
    "        Field(name=\"required_experience_is_missing\", dtype=Int64),\n",
    "        Field(name=\"required_education_is_missing\", dtype=Int64),\n",
    "        Field(name=\"industry_is_missing\", dtype=Int64),\n",
    "        Field(name=\"function_is_missing\", dtype=Int64),\n",
    "        Field(name=\"title_length\", dtype=Int64),\n",
    "        Field(name=\"description_length\", dtype=Int64),\n",
    "        Field(name=\"requirements_length\", dtype=Int64),\n",
    "        Field(name=\"company_profile_length\", dtype=Int64),\n",
    "        Field(name=\"benefits_length\", dtype=Int64),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=job_structured_data_source,\n",
    ")\n",
    "\n",
    "# Define the Text Features data source\n",
    "job_text_data_source  = FileSource(\n",
    "    name='job_text_data',\n",
    "    path=\"data/text_features.parquet\",\n",
    "    timestamp_field=\"event_timestamp\" )\n",
    "\n",
    "# Define the predictor Feature View\n",
    "job_text_features = FeatureView(\n",
    "    name=\"job_text_features_view\",\n",
    "    entities=[job], \n",
    "    ttl=timedelta(days=1),\n",
    "    schema=[\n",
    "        Field(name=\"title_cleaned\", dtype=String),\n",
    "        Field(name=\"description_cleaned\", dtype=String),\n",
    "        Field(name=\"requirements_cleaned\", dtype=String),\n",
    "        Field(name=\"company_profile_cleaned\", dtype=String),\n",
    "        Field(name=\"benefits_cleaned\", dtype=String)\n",
    "    ],\n",
    "    online=True,\n",
    "    source=job_text_data_source,\n",
    ")\n",
    "\n",
    "# Define the target data source\n",
    "job_target_source = FileSource(\n",
    "    name='job_target',\n",
    "    path=\"data/target_features.parquet\",\n",
    "    timestamp_field=\"event_timestamp\")\n",
    "\n",
    "# Define the target Feature View with all columns\n",
    "job_target_features = FeatureView(\n",
    "    name=\"job_target_feature_view\",\n",
    "    entities=[job],\n",
    "    ttl=timedelta(days=1),\n",
    "    schema=[\n",
    "        Field(name=\"fraudulent\", dtype=Int64),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=job_target_source,\n",
    ")\n",
    "'''\n",
    "\n",
    "# Write the content to features.py\n",
    "with open('job_repo/feature_repo/features.py', 'w') as f:\n",
    "    f.write(features_py_content.strip())\n",
    "\n",
    "print(\"Created features.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. feast apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:13.031550Z",
     "start_time": "2024-11-20T10:51:10.632113Z"
    }
   },
   "outputs": [],
   "source": [
    "!cd job_repo/feature_repo && feast apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Extract features from feature stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:14.772463Z",
     "start_time": "2024-11-20T10:51:14.412904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the store\n",
    "store = FeatureStore('job_repo/feature_repo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:24.525810Z",
     "start_time": "2024-11-20T10:51:24.521568Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Simulate the scenario we want a bunch of 'job_id' that created recently\n",
    "today = pd.Timestamp(datetime.now().date()) \n",
    "entity_df = target_features[target_features['event_timestamp'] >= today][['job_id', 'event_timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:26.856991Z",
     "start_time": "2024-11-20T10:51:25.120252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve predictors and target from different features view\n",
    "training_data = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"job_structured_features_view:location\",\n",
    "        \"job_structured_features_view:employment_type\",\n",
    "        \"job_structured_features_view:required_experience\",\n",
    "        \"job_structured_features_view:required_education\",\n",
    "        \"job_structured_features_view:industry\",\n",
    "        \"job_structured_features_view:function\",\n",
    "        \"job_structured_features_view:telecommuting\",\n",
    "        \"job_structured_features_view:has_company_logo\",\n",
    "        \"job_structured_features_view:has_questions\",\n",
    "        \"job_structured_features_view:no_logo_no_questions\",\n",
    "        \"job_structured_features_view:location_freq\",\n",
    "        \"job_structured_features_view:employment_type_freq\",\n",
    "        \"job_structured_features_view:required_experience_freq\",\n",
    "        \"job_structured_features_view:required_education_freq\",\n",
    "        \"job_structured_features_view:industry_freq\",\n",
    "        \"job_structured_features_view:function_freq\",\n",
    "        \"job_structured_features_view:description_is_missing\",\n",
    "        \"job_structured_features_view:requirements_is_missing\",\n",
    "        \"job_structured_features_view:company_profile_is_missing\",\n",
    "        \"job_structured_features_view:benefits_is_missing\",\n",
    "        \"job_structured_features_view:location_is_missing\",\n",
    "        \"job_structured_features_view:employment_type_is_missing\",\n",
    "        \"job_structured_features_view:required_experience_is_missing\",\n",
    "        \"job_structured_features_view:required_education_is_missing\",\n",
    "        \"job_structured_features_view:industry_is_missing\",\n",
    "        \"job_structured_features_view:function_is_missing\",\n",
    "        \"job_structured_features_view:title_length\",\n",
    "        \"job_structured_features_view:description_length\",\n",
    "        \"job_structured_features_view:requirements_length\",\n",
    "        \"job_structured_features_view:company_profile_length\",\n",
    "        \"job_structured_features_view:benefits_length\",\n",
    "        \"job_text_features_view:title_cleaned\",\n",
    "        \"job_text_features_view:description_cleaned\",\n",
    "        \"job_text_features_view:requirements_cleaned\",\n",
    "        \"job_text_features_view:company_profile_cleaned\",\n",
    "        \"job_text_features_view:benefits_cleaned\",\n",
    "        \"job_target_feature_view:fraudulent\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to DataFrame for inspection\n",
    "training_data_df = training_data.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:29.024472Z",
     "start_time": "2024-11-20T10:51:29.017675Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping the columns 'job_id' and 'event_timestamp' from training_data_df\n",
    "training_data_df = training_data_df.drop(columns=['job_id', 'event_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:29.381489Z",
     "start_time": "2024-11-20T10:51:29.372834Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Combined text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T10:51:32.058800Z",
     "start_time": "2024-11-20T10:51:31.536143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine Text Features\n",
    "text_columns = ['title_cleaned', 'company_profile_cleaned', 'description_cleaned', 'requirements_cleaned', 'benefits_cleaned']\n",
    "training_data_df['cleaned_combined_text'] = training_data_df[text_columns].agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:03:38.550552Z",
     "start_time": "2024-11-20T11:03:38.543007Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_df= training_data_df.drop(columns=text_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:09:38.339052Z",
     "start_time": "2024-11-20T11:09:38.332456Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:05:05.373245Z",
     "start_time": "2024-11-20T11:05:03.669593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(training_data_df['cleaned_combined_text'])\n",
    "\n",
    "# Feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert to DataFrame (optional)\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:05:08.210877Z",
     "start_time": "2024-11-20T11:05:08.207606Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:05:41.868641Z",
     "start_time": "2024-11-20T11:05:34.948253Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=500)  \n",
    "X_tfidf_reduced = svd.fit_transform(X_tfidf)\n",
    "tfidf_df_reduced = pd.DataFrame(X_tfidf_reduced, columns=[f'svd_{i}' for i in range(500)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:10:42.599995Z",
     "start_time": "2024-11-20T11:10:42.593579Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_df = training_data_df.drop(columns=['cleaned_combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:10:44.266375Z",
     "start_time": "2024-11-20T11:10:44.212932Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_with_tfidf = pd.concat([training_data_df.reset_index(drop=True), tfidf_df_reduced], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:10:46.691652Z",
     "start_time": "2024-11-20T11:10:46.683736Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data_with_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T11:20:48.740687Z",
     "start_time": "2024-11-20T11:20:47.338997Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save DataFrame to Parquet for temporary usage\n",
    "training_data_with_tfidf.to_parquet(\"training_data_with_tfidf.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building\n",
    "\n",
    "The target for this dataset is 'fraudulent', which is a binary variable of 0 or 1 to indicate if the listing is fraudulent or not (0 for not, 1 for is fraudulent). AUC-Precision-Recall will be used as the metric for best performance as it provides the best balance of the business problem: We want people to be safe from applying to fake jobs as they risk their information getting leaked or scammed, and at the same time want people to have trust in the system so that legitimate jobs don't get flagged as spam. F1-Score was not available as a metric for H2O to rank models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `mlflow ui` in the terminal and go to http://127.0.0.1:5000 to look at the logged runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_371\"; Java(TM) SE Runtime Environment (build 1.8.0_371-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.371-b11, mixed mode)\n",
      "  Starting server from /Users/devondelgado/miniconda3/envs/mlops/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/b4/nhbrf4ws253b52n__dgvd0gr0000gn/T/tmp0f7g8lle\n",
      "  JVM stdout: /var/folders/b4/nhbrf4ws253b52n__dgvd0gr0000gn/T/tmp0f7g8lle/h2o_devondelgado_started_from_python.out\n",
      "  JVM stderr: /var/folders/b4/nhbrf4ws253b52n__dgvd0gr0000gn/T/tmp0f7g8lle/h2o_devondelgado_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Chicago</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>23 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_devondelgado_s1uc18</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.541 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>10</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.15 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Chicago\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    23 days\n",
       "H2O_cluster_name:           H2O_from_python_devondelgado_s1uc18\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.541 Gb\n",
       "H2O_cluster_total_cores:    10\n",
       "H2O_cluster_allowed_cores:  10\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.15 final\n",
       "--------------------------  -----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "15:34:12.150: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "██\n",
      "15:36:26.830: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "████████████████████\n",
      "15:38:30.871: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "██\n",
      "15:39:09.629: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "█████████████\n",
      "15:41:18.21: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "██\n",
      "15:42:04.306: _train param, Dropping bad and constant columns: [description_is_missing]\n",
      "\n",
      "████████████████████████| (done) 100%\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "🏃 View run Leader_Model_Run at: http://127.0.0.1:5000/#/experiments/0/runs/a5b53a765cd0473eaf77639274dd5a6d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "🏃 View run Second_Best_Run at: http://127.0.0.1:5000/#/experiments/0/runs/89d2ad28b6914d22902eb3651a6f6811\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "from mlflow_runner import run_mlflow_pipeline\n",
    "\n",
    "run_mlflow_pipeline('training_data_with_tfidf.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
